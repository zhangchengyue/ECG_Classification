{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbhao4trdW8l"
      },
      "source": [
        "# Convolutional autoencoder for image denoising\n",
        "[See Supplementary Table 3~5 for Model Details](https://static-content.springer.com/esm/art%3A10.1038%2Fs41746-020-00320-4/MediaObjects/41746_2020_320_MOESM1_ESM.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b9LX8b5dW8m"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CZ5rprNrdW8m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "\n",
        "# def preprocess(array):\n",
        "#     \"\"\"Normalizes the supplied array and reshapes it.\"\"\"\n",
        "#     array = array.astype(\"float32\") / 255.0\n",
        "#     array = np.reshape(array, (len(array), 800, 1))\n",
        "#     return array\n",
        "\n",
        "\n",
        "def noise(array, noise_factor = 0.4):\n",
        "    \"\"\"Adds random noise to each image in the supplied array.\"\"\"\n",
        "    noisy_array = array + noise_factor * np.random.normal(\n",
        "        loc=0.0, scale=1.0, size=array.shape\n",
        "    )\n",
        "\n",
        "    return np.clip(noisy_array, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def display(array1, array2, n = 4):\n",
        "    \"\"\"Displays <n> random signals from each array.\"\"\"\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    signals1 = array1[indices, :]\n",
        "    signals2 = array2[indices, :]\n",
        "\n",
        "    plt.figure(figsize=(20, n))\n",
        "    for i, (signal1, signal2) in enumerate(zip(signals1, signals2)):\n",
        "        # Original signal\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.plot(signal1)\n",
        "        plt.title(\"Original\")\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # Noisy signal\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.plot(signal2)\n",
        "        plt.title(\"Noisy\")\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def check_nan(data):\n",
        "    \"\"\"Check whether there are samples with NaN in data.\"\"\"\n",
        "    with_nan = 0\n",
        "    nan_index = []\n",
        "    for i in range(len(data)):\n",
        "        if np.any(np.isnan(data[i])):  # Check whethere there are data with NaN\n",
        "            with_nan += 1\n",
        "            nan_index.append(i)\n",
        "    return with_nan, nan_index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJoIQefVdW8m"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "Obtain the data from [https://www.synapse.org/Synapse:syn21985690](https://www.synapse.org/Synapse:syn21985690)\n",
        "You will need to sign in with an account to access it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2803934, 800, 1)\n",
            "(17617, 800, 1)\n",
            "(518782, 800, 1)\n"
          ]
        }
      ],
      "source": [
        "# Path to .npz files\n",
        "train_npz_path = \"../data/train.npz\"\n",
        "test_npz_path = \"../data/test.npz\"\n",
        "validate_npz_path = \"../data/validate.npz\"\n",
        "\n",
        "# Load data\n",
        "train_npz = np.load(train_npz_path, allow_pickle=True)\n",
        "test_npz = np.load(test_npz_path, allow_pickle=True)\n",
        "validate_npz = np.load(validate_npz_path, allow_pickle=True)\n",
        "\n",
        "# Signals\n",
        "train_data = train_npz[\"signal\"]\n",
        "test_data = test_npz[\"signal\"]\n",
        "validate_data = validate_npz[\"signal\"]\n",
        "\n",
        "# Rhythm labels\n",
        "train_labels_rhythm = train_npz[\"rhythm\"]\n",
        "test_labels_rhythm = test_npz[\"rhythm\"]\n",
        "validate_labels_rhythm = validate_npz[\"rhythm\"]\n",
        "\n",
        "# Quality Assessment labels\n",
        "train_labels_qa = train_npz[\"qa_label\"]\n",
        "test_labels_qa = test_npz[\"qa_label\"]\n",
        "validate_labels_qa = validate_npz[\"qa_label\"]\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(validate_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For demonstration purpose only, we will only be using a subset of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_size = 10000\n",
        "test_size = 500\n",
        "validate_size = 600\n",
        "\n",
        "# Randomly choose samples\n",
        "train_indices = np.random.choice(train_data.shape[0], size=train_size, replace=False)\n",
        "test_indices = np.random.choice(test_data.shape[0], size=test_size, replace=False)\n",
        "validate_indices = np.random.choice(validate_data.shape[0], size=validate_size, replace=False)\n",
        "\n",
        "# Train, Test, Validate (Subsets)\n",
        "train_data = train_data[train_indices]\n",
        "test_data = test_data[test_indices]\n",
        "validate_data = validate_data[validate_indices]\n",
        "\n",
        "# Labels\n",
        "train_labels_rhythm = train_labels_rhythm[train_indices]\n",
        "test_labels_rhythm = test_labels_rhythm[test_indices]\n",
        "validate_labels_rhythm = validate_labels_rhythm[validate_indices]\n",
        "\n",
        "train_labels_qa = train_labels_qa[train_indices]\n",
        "test_labels_qa = test_labels_qa[test_indices]\n",
        "validate_labels_qa = validate_labels_qa[validate_indices]\n",
        "\n",
        "print(\"Train data subset shape:\", train_data.shape)\n",
        "print(\"Test data subset shape:\", test_data.shape)\n",
        "print(\"Validate data subset shape:\", validate_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove NaN samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(check_nan(train_data))\n",
        "print(check_nan(test_data))\n",
        "print(check_nan(validate_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure we check for NaNs across all dimensions except the first\n",
        "valid_train_mask = ~np.isnan(train_data).any(axis=tuple(range(1, train_data.ndim)))\n",
        "valid_test_mask = ~np.isnan(test_data).any(axis=tuple(range(1, test_data.ndim)))\n",
        "valid_validate_mask = ~np.isnan(validate_data).any(axis=tuple(range(1, validate_data.ndim)))\n",
        "\n",
        "# Apply the mask to remove rows with NaNs\n",
        "train_data = train_data[valid_train_mask]\n",
        "test_data = test_data[valid_test_mask]\n",
        "validate_data = validate_data[valid_validate_mask]\n",
        "\n",
        "train_labels_rhythm = train_labels_rhythm[valid_train_mask]\n",
        "test_labels_rhythm = test_labels_rhythm[valid_test_mask]\n",
        "validate_labels_rhythm = validate_labels_rhythm[valid_validate_mask]\n",
        "\n",
        "train_labels_qa = train_labels_qa[valid_train_mask]\n",
        "test_labels_qa = test_labels_qa[valid_test_mask]\n",
        "validate_labels_qa = validate_labels_qa[valid_validate_mask]\n",
        "\n",
        "print(\"Train data subset shape after removing NaN:\", train_data.shape)\n",
        "print(\"Test data subset shape after removing NaN:\", test_data.shape)\n",
        "print(\"Validate data subset shape after removing NaN:\", validate_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy of the data with added noise\n",
        "noise_levels = [0.001, 0.25, 0.5, 0.75, 1, 2, 5]\n",
        "noisy_train_data = []\n",
        "noisy_test_data = []\n",
        "noisy_validate_data = []\n",
        "for noise_factor in noise_levels:\n",
        "    noisy_train_data.append(noise(train_data, noise_factor = noise_factor))\n",
        "    noisy_test_data.append(noise(test_data, noise_factor = noise_factor))\n",
        "    noisy_validate_data.append(noise(validate_data, noise_factor = noise_factor))\n",
        "\n",
        "# Display the train data with added noise\n",
        "for i in range(len(noise_levels)):\n",
        "    print(f\"Noise Factor: {noise_levels[i]}\")\n",
        "    display(train_data, noisy_train_data[i])\n",
        "\n",
        "# Comcatenate all noisy images to become a whole dataset\n",
        "simulated_noisy_train_data = np.concatenate(noisy_train_data, axis=0)\n",
        "simulated_noisy_test_data = np.concatenate(noisy_test_data, axis=0)\n",
        "simulated_noisy_validate_data = np.concatenate(noisy_validate_data, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure there's no NaN samples\n",
        "print(check_nan(simulated_noisy_train_data))\n",
        "print(check_nan(simulated_noisy_test_data))\n",
        "print(check_nan(simulated_noisy_validate_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Joi72281dW8n"
      },
      "source": [
        "## Build the autoencoder\n",
        "\n",
        "We are going to use the Functional API to build our convolutional autoencoder.\n",
        "\n",
        "[See Supplementary Table 3 for CDAE Model Details](https://static-content.springer.com/esm/art%3A10.1038%2Fs41746-020-00320-4/MediaObjects/41746_2020_320_MOESM1_ESM.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "_sM4zpuddW8n",
        "outputId": "b71c98b8-aac0-4e9a-dfa5-f2b4692f8bae"
      },
      "outputs": [],
      "source": [
        "from keras.initializers import he_normal\n",
        "\n",
        "# Input Layer\n",
        "input_layer = layers.Input(shape=(800, 1)) \n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv1D(filters=64, kernel_size=10, activation='relu', padding='same', kernel_initializer=he_normal())(input_layer)\n",
        "x = layers.MaxPooling1D(pool_size=3)(x)  \n",
        "x = layers.Conv1D(filters=45, kernel_size=8, activation='relu', padding='same', kernel_initializer=he_normal())(x)\n",
        "x = layers.MaxPooling1D(pool_size=3)(x)  \n",
        "x = layers.Conv1D(filters=50, kernel_size=5, activation='relu', padding='same', kernel_initializer=he_normal())(x)\n",
        "cdae_encoder = layers.MaxPooling1D(pool_size=2)(x) \n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv1D(filters=50, kernel_size=5, activation='relu', padding='same', kernel_initializer=he_normal())(cdae_encoder)\n",
        "x = layers.UpSampling1D(size=2)(x) \n",
        "x = layers.Conv1D(filters=45, kernel_size=8, activation='relu', padding='same', kernel_initializer=he_normal())(x)\n",
        "x = layers.UpSampling1D(size=3)(x)  \n",
        "x = layers.Conv1D(filters=64, kernel_size=10, activation='relu', padding='same', kernel_initializer=he_normal())(x)\n",
        "x = layers.UpSampling1D(size=3)(x)  \n",
        "\n",
        "# Flatten\n",
        "x = layers.Flatten()(x)  # (None, 792, 64) -> (None, 792 * 64) = (None, 50688)\n",
        "\n",
        "# Dense\n",
        "x = layers.Dense(units=800, activation='relu', kernel_initializer=he_normal())(x)  # (None, 50688) -> (None, 800)\n",
        "\n",
        "# Reshape to match input shape\n",
        "x = layers.Reshape((800, 1))(x)  # (None, 800) -> (None, 800, 1)\n",
        "\n",
        "# Build CDAE model\n",
        "cdae = Model(inputs=input_layer, outputs=x)\n",
        "cdae.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Print structure\n",
        "cdae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train CDAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3L5B1wsdW8n"
      },
      "source": [
        "Now we can train our autoencoder using the noisy\n",
        "data as our input and the clean data as our target. We want our autoencoder to\n",
        "learn how to denoise the images. Notice we are setting up the validation data using the same\n",
        "format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"simulated_noisy_train_data shape:\", simulated_noisy_train_data.shape)\n",
        "print(\"train_data shape before tiling:\", train_data.shape)\n",
        "print(\"y shape after tiling:\", np.tile(train_data, (len(noise_levels), 1, 1)).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17mYyCiTdW8n"
      },
      "outputs": [],
      "source": [
        "# Initial learning rate\n",
        "initial_lr = 0.01\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch % 25 == 0 and epoch > 0:\n",
        "        return max(lr - 0.001, 0.0001)  # Make sure the learning rate does not become negative\n",
        "    return lr\n",
        "\n",
        "lr_reduction = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "\n",
        "# Train Autoencoder\n",
        "history = cdae.fit(\n",
        "    # The input to the CDAE was the simulated signal dataset\n",
        "    # with a Gaussian noise factor of 0.001, 0.5, 0.25, 0.75,\n",
        "    # 1, 2, and 5 added to corrupt the simulated signals.\n",
        "    x=simulated_noisy_train_data,\n",
        "\n",
        "    # The uncorrupted simulated signals are then used as the\n",
        "    # target for reconstruction.\n",
        "    y=np.tile(train_data, (len(noise_levels), 1, 1)),\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(simulated_noisy_validate_data, np.tile(validate_data, (len(noise_levels), 1, 1))),\n",
        "    callbacks=[lr_reduction]\n",
        ")\n",
        "\n",
        "print(history.history) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use CDAE for prediction\n",
        "\n",
        "Let's now predict on the noisy data and display the results of our autoencoder.\n",
        "\n",
        "Notice how the autoencoder does an amazing job at removing the noise from the\n",
        "input images.\n",
        "\n",
        "Since now I'm only using a very tiny subset of the dataset, it makes sense that the model is performing very badly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJVQpK8edW8n"
      },
      "outputs": [],
      "source": [
        "predictions = cdae.predict(test_data)\n",
        "display(test_data, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning\n",
        "\n",
        "[See here for tutorial](https://keras.io/guides/transfer_learning/)\n",
        "\n",
        "The typical transfer-learning workflow\n",
        "\n",
        "This leads us to how a typical transfer learning workflow can be implemented in Keras:\n",
        "\n",
        "1. Instantiate a base model and load pre-trained weights (from pre-trained CDAE as illustrated above) into it.\n",
        "2. Freeze all layers in the base model by setting <code>trainable = False</code>.\n",
        "3. Create a new model (DeepBeat Architecture) on top of the output of one (or several) layers from the base model.\n",
        "4. Train your new model on your new dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain pre-trained CDAE encoder weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cdae_encoder_weights = cdae.get_weights()[:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepBeat Architecture (Multi-Task Learning)\n",
        "TODO: Modify the code based on the workflow.\n",
        "\n",
        "[See Supplementary Table 5 for Model Details](https://static-content.springer.com/esm/art%3A10.1038%2Fs41746-020-00320-4/MediaObjects/41746_2020_320_MOESM1_ESM.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shared Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input Layer\n",
        "input_layer = layers.Input(shape=(800, 1)) \n",
        "\n",
        "# 1. Encoder (Base Model).\n",
        "# Use pre-trained CDAE encoder weights here\n",
        "x = layers.Conv1D(filters=64, kernel_size = 10, activation='relu', padding='same')(input_layer)\n",
        "x = layers.MaxPooling1D(pool_size=3)(x)  \n",
        "x = layers.Conv1D(filters=45, kernel_size = 8, activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling1D(pool_size=3)(x)  \n",
        "x = layers.Conv1D(filters=50, kernel_size=5, activation='relu', padding='same')(x)\n",
        "base_model = layers.MaxPooling1D(pool_size=2)(x) \n",
        "\n",
        "# 2. Define model\n",
        "encoder_model = Model(inputs=input_layer, outputs=base_model, name=\"encoder_model\")\n",
        "\n",
        "# 3. Load pre-trained encoder weights\n",
        "encoder_model.set_weights(cdae_encoder_weights)\n",
        "\n",
        "# 4. Freeze encoder layers\n",
        "encoder_model.trainable = False  \n",
        "\n",
        "# 5. Build base model\n",
        "base_model = encoder_model(input_layer)\n",
        "\n",
        "# 3. Create new model on top of base model\n",
        "# DeepBeat Architecture:\n",
        "# Shared Layers\n",
        "shared_input = layers.BatchNormalization()(base_model)\n",
        "\n",
        "x = layers.Conv1D(filters=64, kernel_size=6, strides = 3, padding='same')(shared_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "x = layers.Conv1D(filters=35, kernel_size=5, strides = 3, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "shared_layers = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Build shared_layers model\n",
        "shared = Model(inputs=shared_input, outputs=shared_layers, name = \"DeepBeat_shared_layers\")\n",
        "shared.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Print structure\n",
        "shared.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rhythm Branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rythm = layers.Conv1D(filters=35, kernel_size=2, strides = 3, padding='same')(shared_layers)\n",
        "rythm = layers.BatchNormalization()(rythm)\n",
        "rythm = layers.Dropout(0.5)(rythm)\n",
        "\n",
        "rythm = layers.Conv1D(filters=25, kernel_size=2, strides = 3, padding='same')(rythm)\n",
        "rythm = layers.BatchNormalization()(rythm)\n",
        "rythm = layers.Dropout(0.5)(rythm)\n",
        "\n",
        "rythm = layers.Conv1D(filters=35, kernel_size=2, padding='same')(rythm)\n",
        "rythm = layers.BatchNormalization()(rythm)\n",
        "rythm = layers.Dropout(0.5)(rythm)\n",
        "\n",
        "rythm = layers.Flatten()(rythm)\n",
        "rythm = layers.Dense(175, activation='relu')(rythm)\n",
        "rythm = layers.Dense(2, activation='softmax')(rythm)\n",
        "\n",
        "# Build rhythm_branch model\n",
        "rhythm_branch = Model(inputs=input_layer, outputs=rythm, name = \"Rhythm_Branch\")\n",
        "rhythm_branch.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Print structure\n",
        "rhythm_branch.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quality Assessment Branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qa = layers.Conv1D(filters=25, kernel_size=3, strides=2, padding='same')(shared_layers)\n",
        "qa = layers.BatchNormalization()(qa)\n",
        "qa = layers.Dropout(0.5)(qa)\n",
        "qa = layers.Flatten()(qa)\n",
        "qa = layers.Dense(175, activation='relu')(qa)\n",
        "qa = layers.Dense(3, activation='softmax')(qa)\n",
        "\n",
        "# Build multi-task learning model\n",
        "qa_branch = Model(inputs=input_layer, outputs=qa, name = \"Quality_Assessment_Branch\")\n",
        "qa_branch.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Print structure\n",
        "qa_branch.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The complete multi-task learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "multitask = Model(inputs=input_layer, outputs=[rythm, qa], name = \"Multi-task_learning_model\")\n",
        "multitask.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Print structure\n",
        "multitask.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train each model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rhythm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial learning rate\n",
        "initial_lr = 0.01\n",
        "\n",
        "lr_reduction = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "\n",
        "# Train Autoencoder\n",
        "rhythm_history = rhythm_branch.fit(\n",
        "    x=train_data,\n",
        "    y= train_labels_rhythm,\n",
        "    epochs=3,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(validate_data, validate_labels_rhythm),\n",
        "    callbacks=[lr_reduction]\n",
        ")\n",
        "\n",
        "print(rhythm_history.history) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rhythm_predictions = rhythm_branch.predict(test_data)\n",
        "display(test_data, rhythm_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_rhythm_labels = np.argmax(rhythm_predictions, axis=1)\n",
        "\n",
        "predicted_rhythm_labels_one_hot = np.eye(2)[predicted_rhythm_labels]\n",
        "\n",
        "print(\"Predicted Rhythm labels:\")\n",
        "print(predicted_rhythm_labels_one_hot[:5])\n",
        "\n",
        "print(\"True Rhythm labels:\")\n",
        "print(test_labels_rhythm[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial learning rate\n",
        "initial_lr = 0.01\n",
        "\n",
        "lr_reduction = LearningRateScheduler(lr_schedule, verbose=1)\n",
        "\n",
        "# Train Autoencoder\n",
        "qa_history = qa_branch.fit(\n",
        "    x=train_data,\n",
        "    y = train_labels_qa,\n",
        "    epochs=3,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(validate_data, validate_labels_qa),\n",
        "    callbacks=[lr_reduction]\n",
        ")\n",
        "\n",
        "print(qa_history.history) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qa_predictions = qa_branch.predict(test_data)\n",
        "display(test_data, qa_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_qa_labels = np.argmax(qa_predictions, axis=1)\n",
        "\n",
        "predicted_qa_labels_one_hot = np.eye(3)[predicted_qa_labels]\n",
        "\n",
        "print(\"Predicted QA labels:\")\n",
        "print(predicted_qa_labels_one_hot[:5])\n",
        "\n",
        "print(\"True QA labels:\")\n",
        "print(test_labels_qa[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score, precision_score\n",
        "\n",
        "# Convert one-hot encoding to class labels\n",
        "y_true_rhythm_cls = np.argmax(test_labels_rhythm, axis=1)\n",
        "y_pred_rhythm_cls = predicted_rhythm_labels\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true_rhythm_cls, y_pred_rhythm_cls)\n",
        "\n",
        "# Extract TP, FP, FN, TN for binary classification\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "# Compute performance metrics\n",
        "sensitivity = TP / (TP + FN)  # Recall\n",
        "specificity = TN / (TN + FP)\n",
        "fpr = FP / (FP + TN)  # False Positive Rate\n",
        "fnr = FN / (FN + TP)  # False Negative Rate\n",
        "f1 = f1_score(y_true_rhythm_cls, y_pred_rhythm_cls, average=\"macro\")  # Macro F1-score\n",
        "\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n",
        "print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
        "print(f\"False Negative Rate (FNR): {fnr:.4f}\")\n",
        "print(f\"F1 Score (Macro): {f1:.4f}\")\n",
        "\n",
        "# --- Weighted Macro-Averaged (Handling Class Imbalance) ---\n",
        "# We use `average=\"weighted\"` for weighted macro-average\n",
        "f1_weighted = f1_score(y_true_rhythm_cls, y_pred_rhythm_cls, average=\"weighted\")\n",
        "recall_weighted = recall_score(y_true_rhythm_cls, y_pred_rhythm_cls, average=\"weighted\")\n",
        "precision_weighted = precision_score(y_true_rhythm_cls, y_pred_rhythm_cls, average=\"weighted\")\n",
        "\n",
        "print(\"\\n--- Weighted Macro-Averaged Metrics ---\")\n",
        "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n",
        "print(f\"Weighted Recall (Sensitivity): {recall_weighted:.4f}\")\n",
        "print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
        "\n",
        "# Generate full classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_rhythm_cls, y_pred_rhythm_cls))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
