{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8271f1fc",
   "metadata": {},
   "source": [
    "# Icentia11k Preprocessing\n",
    "\n",
    "> Preprocessing steps for Icentia11k data for use in a multi-task classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f63abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "\n",
    "from ecg_classification.training import make_ecg_data_train_test_split, print_split_summary, DataSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826e1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8-paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c41fef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile '../data/icentia11k/data.npz' with keys: signal, frame_num, beat, rhythm, patient..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(Path(\"../data/icentia11k/data.npz\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4838d52",
   "metadata": {},
   "source": [
    "## Missingness\n",
    "\n",
    "Missing samples in a frame could cause issues in for our classifer, so we should check for that.\n",
    "A quick check reveals there are no missing data in the inputs or the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c69634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal': array([], shape=(0, 2), dtype=int64),\n",
       " 'rhythm': array([], shape=(0, 1), dtype=int64),\n",
       " 'beat': array([], shape=(0, 1), dtype=int64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_missingness_in_ecg_data(data: dict[str, npt.NDArray]) -> dict[str, float]:\n",
    "    \"\"\"Checks for missing data in ECG data. Returns a list of indices where there are missing data\"\"\"\n",
    "    return {\n",
    "        \"signal\": np.argwhere(np.isnan(data[\"signal\"])),\n",
    "        \"rhythm\": np.argwhere(np.isnan(data[\"rhythm\"])),\n",
    "        \"beat\": np.argwhere(np.isnan(data[\"beat\"]))\n",
    "    }\n",
    "\n",
    "check_missingness_in_ecg_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d241ab8",
   "metadata": {},
   "source": [
    "## Train/Test Splits\n",
    "\n",
    "In a nutshell, we want to design a model that will predict two different tasks: 1) identifying beat abnormalities and 2) identifying rhythm abnormalities.\n",
    "\n",
    "We have good reason to believe there is some shared underlying structure between the two tasks because they both involve aspects of the same underlying ECG signal.\n",
    "\n",
    "For a multi-task model, we want two different, but related, datasets:\n",
    "1. Input ECG Signal, Beat labels\n",
    "2. Input ECG Signal, Rhythm labels\n",
    "\n",
    "but we want to make sure that the the input frames from one patient don't end up in both train and test because that might leak information the model wouldn't have access to.\n",
    "\n",
    "To decide if we stratify-group-split by beat labels or by rhythm labels we should know which aspect would benefit more from the stratification. Because abnormal rhythm class is more rare, we should stratify by that to increase the chance that there is some abnormal rhythm examples in the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d23b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (31440, 800)\n",
      "Test: (15720, 800)\n"
     ]
    }
   ],
   "source": [
    "train, test = make_ecg_data_train_test_split(data, test_size=0.3, random_state=42)\n",
    "print(\"Train:\", train.X.shape)\n",
    "print(\"Test:\", test.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739010bd",
   "metadata": {},
   "source": [
    "## Addressing Class Imbalances\n",
    "\n",
    "First, let's inspect the class imbalances in the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e61f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split (31440, 800)\n",
      "3525/31440 (0.1121) abnormal beats\n",
      "34/31440 (0.0011) abnormal rhythms\n",
      "\n",
      "test split (15720, 800)\n",
      "46/15720 (0.0029) abnormal beats\n",
      "277/15720 (0.0176) abnormal rhythms\n"
     ]
    }
   ],
   "source": [
    "print_split_summary(train)\n",
    "print()\n",
    "print_split_summary(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedb1d6",
   "metadata": {},
   "source": [
    "There are many strategies to address class imbalances (refer to [Chapter 16 from Applied Predictive Modelling (Kuhn & Johnson, 2013)](https://vuquangnguyen2016.wordpress.com/wp-content/uploads/2018/03/applied-predictive-modeling-max-kuhn-kjell-johnson_1518.pdf))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Given the heavy class imbalance in the training set, it is appropriate to oversample.\n",
    "But remember NOT to oversample in the test set!\n",
    "\n",
    "Oversampling - Due to the time-series data, we can't use [SMOTE](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "\n",
    "I tried resampling, but that didn't work as well as I wanted - it just kept the relative proportions of classes the same ...\n",
    "\n",
    "\n",
    "Trying to synthetically resample time series data is ... complicated\n",
    "1. T-SMOTE [https://www.ijcai.org/proceedings/2022/0334.pdf](https://www.ijcai.org/proceedings/2022/0334.pdf)\n",
    "2. tSMOTE [https://arxiv.org/abs/2201.05634](https://arxiv.org/abs/2201.05634)\n",
    "\n",
    "\n",
    "For now, we will move the problem to the model and simply adjust the cost function such that more penalty weight is given to getting the minority class wrong \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04968af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import math\n",
    "from ecg_classification.training import randomly_oversample_minority_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44863a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split (34602, 800)\n",
      "3525/34602 (0.1019) abnormal beats\n",
      "3196/34602 (0.0924) abnormal rhythms\n"
     ]
    }
   ],
   "source": [
    "print_split_summary(randomly_oversample_minority_class(train, 0.1, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b14c0a",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "As we apply preprocessing steps, it's important to visualize transformations of the signals.\n",
    "\n",
    "Importantly, let's be sure to only inspect the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecg_classification.visualize import plot_ecg, plot_multiple_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of frame with normal beat and rhythm\n",
    "plot_ecg(train.X[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of frame with abnormal rhythm\n",
    "plot_ecg(train.X[np.argwhere(train.y_rhythm == 1)[0][0]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of frame with abnormal beat\n",
    "plot_ecg(train.X[np.argwhere(train.y_beat == 1)[0][0]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92224581",
   "metadata": {},
   "source": [
    "## Signal Pre-Processing\n",
    "\n",
    "Based on the visuals above, it appears we should apply a few key preprocessing steps\n",
    "\n",
    "1. Smooth (moving average filter)\n",
    "2. Detrend\n",
    "3. Normalize\n",
    "\n",
    "More information here:\n",
    "\n",
    "1. [Salimi et al. 2023](https://arxiv.org/pdf/2311.04229)\n",
    "2. [https://www.dspguide.com/](https://www.dspguide.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecg_classification.preprocessing import preprocess_ecg_signals\n",
    "preprocessed_train = preprocess_ecg_signals(train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab92af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 1050\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 3))\n",
    "time = np.arange(preprocessed_train.shape[1])\n",
    "ax.plot(time, train.X[frame], label=\"raw\")\n",
    "ax.plot(time, preprocessed_train[frame], label=\"preprocessed\")\n",
    "ax.set_title(\n",
    "    f\"Raw vs Preprocessed ECG recording ({frame=}, beat={train.y_beat[frame]}, rhythm={train.y_rhythm[frame]})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b6e52d",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "We must ensure that when performing cross-validation, we group by patient and stratify by class and preserve the temporal order of frames.\n",
    "\n",
    "In other words, if we have $N$ patients in the training set, we train our model on $k$ patients and validate on $N - k$ patients, while ensuring the \n",
    "\n",
    "We (unrealistically) assume that segments of ECG signals are independent. This simplifying assumption is somewhat reasonable as Tan et al. 2019 derived segments by taking a random subset of ECG recording slices. We assume the segments were spaced out enough in time to not be correlated segments that occurred earlier in time.\n",
    "\n",
    "Other approaches:\n",
    "- [Mathworks: Classify ECG Signal](https://www.mathworks.com/help/signal/ug/classify-ecg-signals-using-long-short-term-memory-networks.html) - used random shuffling, because they had one 9000-sample long window of ECG signal for each patient. Bc each signal was from different patients, they were not temporally correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830781bc",
   "metadata": {},
   "source": [
    "## Evaluating Several Different Classifiers\n",
    "\n",
    "### Implications for Modelling\n",
    "\n",
    "[Calibrating a classifier - Scikit-Learn](https://scikit-learn.org/stable/modules/calibration.html#calibrating-a-classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a004d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
